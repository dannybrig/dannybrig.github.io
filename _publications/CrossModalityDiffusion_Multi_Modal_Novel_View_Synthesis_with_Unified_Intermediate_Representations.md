---
title: "CrossModalityDiffusion: Multi-Modal Novel View Synthesis with Unified Intermediate Representation"
collection: publications
permalink: /publication/CrossModalityDiffusion_Multi_Modal_Novel_View_Synthesis_with_Unified_Intermediate_Representations
excerpt: 'CrossModalityDiffusion is a modular framework designed to address challenges in interpreting geometry across diverse geospatial imaging modalities, such as EO, SAR, and LiDAR. By employing modality-specific encoders and volumetric rendering techniques, it generates geometry-aware feature volumes that unify inputs from varying viewpoints. '
date: 2025-03-04
venue: 'WACV GeoCV Workshop'
paperurl: # 'https://arxiv.org/abs/2501.09838'
citation: 'Berian, A., Brignac, D., Wu, J., Daba, N., & Mahalanobis, A. CrossModalityDiffusion: Multi-Modal Novel View Synthesis with Unified Intermediate Representation. Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision. 2025.'
---

CrossModalityDiffusion is a modular framework designed to address challenges in interpreting geometry across diverse geospatial imaging modalities, such as EO, SAR, and LiDAR. By employing modality-specific encoders and volumetric rendering techniques, it generates geometry-aware feature volumes that unify inputs from varying viewpoints. 

[Download paper here](http://dannybrig.github.io/files/CrossModalityDiffusion_Multi_Modal_Novel_View_Synthesis_with_Unified_Intermediate_Representations.pdf) \\
[Download code here](https://github.com/alexberian/CrossModalityDiffusion/)